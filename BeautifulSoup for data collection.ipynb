{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cefd628e-2211-4605-835c-a14f3e4de8cb",
   "metadata": {},
   "source": [
    "# BeautifulSoup For Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd5645-c0df-4cbf-a6be-eff681095af4",
   "metadata": {},
   "source": [
    "## 1. What is BeautifulSoup?\n",
    "\n",
    "- BeautifulSoup is a Python library used to parse HTML and XML documents.\n",
    "- It creates a parse tree from page content, making it easy to extract data.\n",
    "- It is often used with requests to scrape websites.\n",
    "\n",
    "## 2. Installing BeautifulSoup\n",
    "\n",
    "- Install both beautifulsoup4 and a parser like lxml:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac95a6c-a06f-4ede-94a4-24d896080b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to anaconda prompt and type : conda install beautifulsoup4 lxml + Enter\n",
    "# Whyyy both package we install i.e beautifulsoup4 and lxml\n",
    "# beautifulsoup4 is a package helps for web scarping\n",
    "# lxml is a another package helps to parse the html and to extract the data most of the cases we use a html.parser but sometimes as lxml\n",
    "# kashi cells sequence ne run karayche te video madhe nit bagh nahitr sagla gandel in data science course of harry bhai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dac525-4d51-4f4b-9058-3cb0813881a6",
   "metadata": {},
   "source": [
    "# 3. Creating a BeautifulSoup Object\n",
    "\n",
    "- response.text: HTML content.\n",
    "- \"lxml\": A fast and powerful parser (you can also use \"html.parser\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2f2481-3219-4d40-8e57-b41f38d56218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25817d1-dcec-480a-af79-41357fc56be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we read the page1.html from htmls folder\n",
    "with open(\"htmls/page1.html\") as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b5edf7-7350-4d01-a49d-4062be6ef640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make the soup from the html content that is page1.html Now, With the help of soup I will extract all things...\n",
    "soup = BeautifulSoup(content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe4fadf9-72c8-4cb7-b479-8a8c4ed10011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now if I want all books name and price what I will do I will go to that website i.e https://books.toscrape.com/catalogue/page-1.html on that 1st book name I will go and I will inspect element\n",
    "# So By inspect elemnt we get to know that book name is in h3 element tag, So what I will do now so from html page i will extract all h3 tags let's see from one by one method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad375a-5f9c-4772-a17c-51303482fcc7",
   "metadata": {},
   "source": [
    "# find_all() Method:\n",
    "\n",
    "- Finds all matching elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e4be553-30af-4d88-8598-6c23cb6890b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will get a all h3 means all books name from page1.html in html form in OUTPUT:\n",
    "h3s = soup.find_all(\"h3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c47472f-6de3-41e6-ae33-fa812e932010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3><a href=\"a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>,\n",
       " <h3><a href=\"tipping-the-velvet_999/index.html\" title=\"Tipping the Velvet\">Tipping the Velvet</a></h3>,\n",
       " <h3><a href=\"soumission_998/index.html\" title=\"Soumission\">Soumission</a></h3>,\n",
       " <h3><a href=\"sharp-objects_997/index.html\" title=\"Sharp Objects\">Sharp Objects</a></h3>,\n",
       " <h3><a href=\"sapiens-a-brief-history-of-humankind_996/index.html\" title=\"Sapiens: A Brief History of Humankind\">Sapiens: A Brief History ...</a></h3>,\n",
       " <h3><a href=\"the-requiem-red_995/index.html\" title=\"The Requiem Red\">The Requiem Red</a></h3>,\n",
       " <h3><a href=\"the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\" title=\"The Dirty Little Secrets of Getting Your Dream Job\">The Dirty Little Secrets ...</a></h3>,\n",
       " <h3><a href=\"the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\" title=\"The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\">The Coming Woman: A ...</a></h3>,\n",
       " <h3><a href=\"the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\" title=\"The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\">The Boys in the ...</a></h3>,\n",
       " <h3><a href=\"the-black-maria_991/index.html\" title=\"The Black Maria\">The Black Maria</a></h3>,\n",
       " <h3><a href=\"starving-hearts-triangular-trade-trilogy-1_990/index.html\" title=\"Starving Hearts (Triangular Trade Trilogy, #1)\">Starving Hearts (Triangular Trade ...</a></h3>,\n",
       " <h3><a href=\"shakespeares-sonnets_989/index.html\" title=\"Shakespeare's Sonnets\">Shakespeare's Sonnets</a></h3>,\n",
       " <h3><a href=\"set-me-free_988/index.html\" title=\"Set Me Free\">Set Me Free</a></h3>,\n",
       " <h3><a href=\"scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\" title=\"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\">Scott Pilgrim's Precious Little ...</a></h3>,\n",
       " <h3><a href=\"rip-it-up-and-start-again_986/index.html\" title=\"Rip it Up and Start Again\">Rip it Up and ...</a></h3>,\n",
       " <h3><a href=\"our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\" title=\"Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\">Our Band Could Be ...</a></h3>,\n",
       " <h3><a href=\"olio_984/index.html\" title=\"Olio\">Olio</a></h3>,\n",
       " <h3><a href=\"mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\" title=\"Mesaerion: The Best Science Fiction Stories 1800-1849\">Mesaerion: The Best Science ...</a></h3>,\n",
       " <h3><a href=\"libertarianism-for-beginners_982/index.html\" title=\"Libertarianism for Beginners\">Libertarianism for Beginners</a></h3>,\n",
       " <h3><a href=\"its-only-the-himalayas_981/index.html\" title=\"It's Only the Himalayas\">It's Only the Himalayas</a></h3>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3832f2d4-60dd-484e-b578-822c30cffc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic\n",
      "Tipping the Velvet\n",
      "Soumission\n",
      "Sharp Objects\n",
      "Sapiens: A Brief History of Humankind\n",
      "The Requiem Red\n",
      "The Dirty Little Secrets of Getting Your Dream Job\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
      "The Black Maria\n",
      "Starving Hearts (Triangular Trade Trilogy, #1)\n",
      "Shakespeare's Sonnets\n",
      "Set Me Free\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\n",
      "Rip it Up and Start Again\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\n",
      "Olio\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849\n",
      "Libertarianism for Beginners\n",
      "It's Only the Himalayas\n"
     ]
    }
   ],
   "source": [
    "for h3 in h3s:\n",
    "    print(h3.find(\"a\")['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef2aab-5272-450d-8d86-37ba65334978",
   "metadata": {},
   "source": [
    "# Explanation for above code : \n",
    "\n",
    "Good question, Yash üëç Let‚Äôs break it down **step-by-step in the simplest way** üëá\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Code:\n",
    "\n",
    "```python\n",
    "for h3 in h3s:\n",
    "    print(h3.find(\"a\")['title'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Explanation:\n",
    "\n",
    "1. **`h3s`** ‚Üí\n",
    "   It is a list of all `<h3>` HTML tags you have found earlier using BeautifulSoup.\n",
    "   Example:\n",
    "\n",
    "   ```html\n",
    "   <h3><a title=\"Restaurant ABC\" href=\"link1.html\"></a></h3>\n",
    "   <h3><a title=\"Restaurant XYZ\" href=\"link2.html\"></a></h3>\n",
    "   ```\n",
    "\n",
    "2. **`for h3 in h3s:`** ‚Üí\n",
    "   This means we are looping through each `<h3>` tag one by one.\n",
    "\n",
    "3. **`h3.find(\"a\")`** ‚Üí\n",
    "   This looks **inside the `<h3>` tag** to find the first `<a>` tag (anchor tag).\n",
    "   `<a>` tag in HTML is used for **links** (hyperlinks).\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```html\n",
    "   <h3><a title=\"Restaurant ABC\" href=\"link1.html\"></a></h3>\n",
    "   ```\n",
    "\n",
    "   Here, `<a>` is the anchor tag.\n",
    "\n",
    "4. **`['title']`** ‚Üí\n",
    "   This extracts the **value of the ‚Äútitle‚Äù attribute** from the `<a>` tag.\n",
    "\n",
    "   Example:\n",
    "   From `<a title=\"Restaurant ABC\" href=\"link1.html\">`,\n",
    "   it will return `\"Restaurant ABC\"`.\n",
    "\n",
    "5. **`print(...)`** ‚Üí\n",
    "   Finally, it prints the value of each title.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Output Example:\n",
    "\n",
    "If the HTML looks like this:\n",
    "\n",
    "```html\n",
    "<h3><a title=\"KFC\" href=\"kfc.html\"></a></h3>\n",
    "<h3><a title=\"Dominos\" href=\"dominos.html\"></a></h3>\n",
    "```\n",
    "\n",
    "Then the code prints:\n",
    "\n",
    "```\n",
    "KFC\n",
    "Dominos\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Summary:\n",
    "\n",
    "| Code Part      | Meaning                       | Real-Life Example         |\n",
    "| -------------- | ----------------------------- | ------------------------- |\n",
    "| `h3s`          | List of all `<h3>` tags       | List of restaurant titles |\n",
    "| `h3.find(\"a\")` | Find link tag inside `<h3>`   | Finds the `<a>` link      |\n",
    "| `['title']`    | Gets value of title attribute | \"KFC\", \"Dominos\"          |\n",
    "| `print()`      | Shows result                  | Displays restaurant names |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42245da-e84b-42b3-b963-1fc4e4ec6693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.77\n",
      "53.74\n",
      "50.10\n",
      "47.82\n",
      "54.23\n",
      "22.65\n",
      "33.34\n",
      "17.93\n",
      "22.60\n",
      "52.15\n",
      "13.99\n",
      "20.66\n",
      "17.46\n",
      "52.29\n",
      "35.02\n",
      "57.25\n",
      "23.88\n",
      "37.59\n",
      "51.33\n",
      "45.17\n"
     ]
    }
   ],
   "source": [
    "# This is the sequence of the cell\n",
    "# from bs4 import BeautifulSoup \n",
    "\n",
    "# with open(\"htmls/page1.html\") as f:\n",
    "#    content = f.read() \n",
    "\n",
    "# soup = BeautifulSoup(content,\"html.parser\")\n",
    "\n",
    "\n",
    "# Ata mala product price kadayche mahanlay var mala parent tag pasna step by step div parynta yeva lagnr jetha product price ahai see inspect element click kelay var hover hot website la\n",
    "articles = soup.select(\"article.product_pod\") # This will print all articles if u print the articles variable\n",
    "\n",
    "# And Then one by one sagle article gheun tay madhle title ghenr\n",
    "\n",
    "for article in articles:\n",
    "    title = article.find(\"h3\").find(\"a\")[\"title\"] # This will print all title of books from page1.html if u print the title find_all not needed here cus we used in article.product_pod\n",
    "    price = article.select_one(\"p.price_color\").text.split(\"¬£\")[1] # Go and see explanation for this code in explanation for bs4 code file, It means get the text content (like the actual price value) from the first `<p class=\"price_color\">` tag inside each article. OUTPUT:√É‚Äö√Ç¬£51.77....so..on, Now We have to split it by ¬£ to remove the √É‚Äö√Ç and I will print text of list index 1 i.e 51.77,53.74,...so..on..  \n",
    "    print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1dc37bf-6ae7-4cf7-b5ba-847c2e357197",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [] # Here I have create an empty list of items so that at last I can append the title and price\n",
    "# Ata mala product price kadayche mahanlay var mala parent tag pasna step by step div parynta yeva lagnr jetha product price ahai see inspect element click kelay var hover hot website la\n",
    "articles = soup.select(\"article.product_pod\") # This will print all articles if u print the articles variable\n",
    "\n",
    "# And Then one by one sagle article gheun tay madhle title ghenr\n",
    "\n",
    "for article in articles:\n",
    "    title = article.find(\"h3\").find(\"a\")[\"title\"] # This will print all title of books from page1.html if u print the title find_all not needed here cus we used in article.product_pod\n",
    "    price = article.select_one(\"p.price_color\").text.split(\"¬£\")[1] # Go and see explanation for this code in explanation for bs4 code file, It means get the text content (like the actual price value) from the first `<p class=\"price_color\">` tag inside each article. OUTPUT:√É‚Äö√Ç¬£51.77....so..on, Now We have to split it by ¬£ to remove the √É‚Äö√Ç and I will print text of list index 1 i.e 51.77,53.74,...so..on..\n",
    "\n",
    "\n",
    "    # Let's Add the rating also for each book for page1.html\n",
    "    rating_element = article.select_one(\"p.star-rating\")\n",
    "    rating = rating_element['class'][1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    items.append([title,price,rating])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e73badb-8c9d-4034-b9cb-9db8e69ac66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A Light in the Attic', '51.77', 'Three'],\n",
       " ['Tipping the Velvet', '53.74', 'One'],\n",
       " ['Soumission', '50.10', 'One'],\n",
       " ['Sharp Objects', '47.82', 'Four'],\n",
       " ['Sapiens: A Brief History of Humankind', '54.23', 'Five'],\n",
       " ['The Requiem Red', '22.65', 'One'],\n",
       " ['The Dirty Little Secrets of Getting Your Dream Job', '33.34', 'Four'],\n",
       " ['The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull',\n",
       "  '17.93',\n",
       "  'Three'],\n",
       " ['The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics',\n",
       "  '22.60',\n",
       "  'Four'],\n",
       " ['The Black Maria', '52.15', 'One'],\n",
       " ['Starving Hearts (Triangular Trade Trilogy, #1)', '13.99', 'Two'],\n",
       " [\"Shakespeare's Sonnets\", '20.66', 'Four'],\n",
       " ['Set Me Free', '17.46', 'Five'],\n",
       " [\"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", '52.29', 'Five'],\n",
       " ['Rip it Up and Start Again', '35.02', 'Five'],\n",
       " ['Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991',\n",
       "  '57.25',\n",
       "  'Three'],\n",
       " ['Olio', '23.88', 'One'],\n",
       " ['Mesaerion: The Best Science Fiction Stories 1800-1849', '37.59', 'One'],\n",
       " ['Libertarianism for Beginners', '51.33', 'Two'],\n",
       " [\"It's Only the Himalayas\", '45.17', 'Two']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [['A Light in the Attic', '51.77'],['Tipping the Velvet', '53.74'],.....so..on...]]\n",
    "items # This is for page1.html,All Books names and price in a items list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e348857-b141-48a0-93ff-9a7d7092302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can convert the above item list in a DataFrame also using a pandas library let see\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10ea3bb9-af2f-4c28-8feb-8e0451095e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(items,columns=['Book Title','Price','Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7937411c-f1b0-4bc5-a3c1-76d25e333e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>51.77</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>53.74</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>50.10</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>47.82</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>54.23</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>22.65</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>33.34</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>17.93</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>22.60</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>52.15</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
       "      <td>13.99</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>20.66</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>17.46</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
       "      <td>52.29</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rip it Up and Start Again</td>\n",
       "      <td>35.02</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
       "      <td>57.25</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Olio</td>\n",
       "      <td>23.88</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
       "      <td>37.59</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>51.33</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>45.17</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Title  Price Rating\n",
       "0                                A Light in the Attic  51.77  Three\n",
       "1                                  Tipping the Velvet  53.74    One\n",
       "2                                          Soumission  50.10    One\n",
       "3                                       Sharp Objects  47.82   Four\n",
       "4               Sapiens: A Brief History of Humankind  54.23   Five\n",
       "5                                     The Requiem Red  22.65    One\n",
       "6   The Dirty Little Secrets of Getting Your Dream...  33.34   Four\n",
       "7   The Coming Woman: A Novel Based on the Life of...  17.93  Three\n",
       "8   The Boys in the Boat: Nine Americans and Their...  22.60   Four\n",
       "9                                     The Black Maria  52.15    One\n",
       "10     Starving Hearts (Triangular Trade Trilogy, #1)  13.99    Two\n",
       "11                              Shakespeare's Sonnets  20.66   Four\n",
       "12                                        Set Me Free  17.46   Five\n",
       "13  Scott Pilgrim's Precious Little Life (Scott Pi...  52.29   Five\n",
       "14                          Rip it Up and Start Again  35.02   Five\n",
       "15  Our Band Could Be Your Life: Scenes from the A...  57.25  Three\n",
       "16                                               Olio  23.88    One\n",
       "17  Mesaerion: The Best Science Fiction Stories 18...  37.59    One\n",
       "18                       Libertarianism for Beginners  51.33    Two\n",
       "19                            It's Only the Himalayas  45.17    Two"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "812d67c3-05f0-442d-815f-3b6907015eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what a Web Scraping is we have also format in a DataFrame in a Structral Table just for a single html page i.e htmls/page1.html sky is the limit u can do whatever u want u can also add the data in xl,csv after scraping it from website before that take all data of websites in this folder structure htmls/page1.html.....so..on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89f80850-5887-4fb2-a0f6-82cc2d3eaad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can export the df in csv file let's do that :\n",
    "df.to_csv(\"data.csv\",index=False) # In csv file index will not come cuz I have done index=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3eb5996-6e81-422d-ba4c-ce5f54023ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tumhi xl madhe jaun filter laun faktha 5 star wale books pan visible karu shakta if tula thoda xl yet asel tr otherwise chatgpt ahich na bhau...ok,that set.ChatGpt la vechar na bhau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798c517-1835-45cf-b3b9-3f5e8475e5d0",
   "metadata": {},
   "source": [
    "# 9. Summary\n",
    "- BeautifulSoup helps parse and navigate HTML easily.\n",
    "- Use .find(), .find_all(), .select(), and .select_one() to locate data.\n",
    "- Always inspect the website's structure before writing scraping logic.\n",
    "- Combine BeautifulSoup with requests for full scraping workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94fa026-e855-492a-b495-e766d1b4a791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
